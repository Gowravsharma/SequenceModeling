{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304e9be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import DatasetDict, Dataset, load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e12519",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "student_model_name = 'meta-llama/Llama-3.2-1B'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "  load_in_4bit = True,\n",
    "  bnb_4bit_quant_type = 'nf4',\n",
    "  bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "teacher_model = AutoModelForCausalLM.from_pretrained(\n",
    "  teacher_model_name,\n",
    "  quantization_config = bnb_config,\n",
    "  device_map = 'auto'\n",
    ")\n",
    "\n",
    "student_model = AutoModelForCausalLM.from_pretrained(\n",
    "  student_model_name,\n",
    "  quantization_config = bnb_config,\n",
    "  device_map = 'auto'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648eadf",
   "metadata": {},
   "source": [
    "dataset format\n",
    "```\n",
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['instruction', 'input', 'output', 'text'],\n",
    "        num_rows: 52002\n",
    "    })\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b988b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('tatsu-lab/alpaca')\n",
    "\n",
    "def format_batch(batch):\n",
    "  if batch['input']:\n",
    "    prompt = f\"Instruction: {batch['instruction']}\\nInput: {batch['input']}\\nOutput:\"\n",
    "  else:\n",
    "    prompt = f\"Instruction: {batch['instruction']}\\nOutput\"\n",
    "  return {\"text\":prompt}\n",
    "\n",
    "dataset = dataset[\"train\"].map(format_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d880ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'How can we reduce air pollution?',\n",
       " 'input': '',\n",
       " 'output': 'There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.',\n",
       " 'text': 'Instruction: How can we reduce air pollution?\\nOutput'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523c70e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b93e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Give three tips for staying healthy.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66aae9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "student_model_name = 'meta-llama/Llama-3.2-1B'\n",
    "\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_model_name)\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_model_name)\n",
    "teacher_tokenizer.pad_token = teacher_tokenizer.eos_token\n",
    "\n",
    "def tokenize(batch):\n",
    "  return teacher_tokenizer(batch[\"text\"], padding = \"max_length\", truncation = True, max_length = 512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched = True).map(tokenize, batched = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6215af1",
   "metadata": {},
   "source": [
    "**Forward Pass With Teacher(NO GRADIENTS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103ddd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9501e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How can we reduce air pollution?',\n",
       " 'Describe a time when you had to make a difficult decision.',\n",
       " 'Identify the odd one out.',\n",
       " 'Explain why the following fraction is equivalent to 1/4',\n",
       " 'Write a short story in third person narration about a protagonist who has to make an important career decision.',\n",
       " 'Render a 3D model of a house',\n",
       " 'Evaluate this sentence for spelling and grammar mistakes']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset[3]['input_ids'])\n",
    "# tokenized_dataset[0]['attention_mask']\n",
    "tokenized_dataset[3:10]['instruction']\n",
    "# len(tokenized_dataset[3]['input_ids']) #512\n",
    "# tokenized_dataset[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d178be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52002"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fbf347",
   "metadata": {},
   "source": [
    "**Boot Strap Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dee4aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import numpy as np\n",
    "\n",
    "class BootstrapSampler(Sampler):\n",
    "  def __init__(self,data_source, num_samples = None, generator = None):\n",
    "    self.data_source = data_source\n",
    "    self.num_samples = num_samples if num_samples is not None else len(data_source)\n",
    "    self.generator = generator\n",
    "\n",
    "  def __iter__(self):\n",
    "    indices = np.random.choice(len(self.data_source), size = self.num_samples,  replace = True )\n",
    "    return iter(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ae52213",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = BootstrapSampler(tokenized_dataset, num_samples = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100b776",
   "metadata": {},
   "source": [
    "**Forward Pass With Teacher(NO GRADIENTS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenized_dataset[0]\n",
    "input_ids = torch.tensor(batch['input_ids']).unsqueeze(0).to(teacher_model.device)\n",
    "mask = torch.tensor(batch['attention_mask']).unsqueeze(0).to(teacher_model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  out = teacher_model(input_ids, attention_mask = mask)\n",
    "  teacher_logits = out.logits #[batch, seq_len, vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430089c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52002, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.shape # (52002, 6) -> (number_roows, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5302f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16a89e6c",
   "metadata": {},
   "source": [
    "**Distillation_loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad33b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "student_out = student_model(input_ids, attention_mask=mask)\n",
    "student_logits = student_out.logits\n",
    "\n",
    "# KL divergence loss\n",
    "loss = F.kl_div(\n",
    "  input=F.log_softmax(student_logits, dim=-1),\n",
    "  target=F.softmax(teacher_logits, dim=-1),\n",
    "  reduction=\"batchmean\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8871fc04",
   "metadata": {},
   "source": [
    "**Train Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f642bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "  return{\n",
    "    \"input_ids\": torch.tensor([x[\"input_ids\"] for x in batch]),\n",
    "    \"attention_mask\": torch.tensor([x[\"attention_mask\"] for x in batch])\n",
    "  }\n",
    "\n",
    "train_loader = DataLoader(tokenized_dataset, batch_size = 4, shuffle = True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f39de753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab04f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optimizer = Adam(student_model.parameters(), lr=1e-5)\n",
    "\n",
    "i = 0\n",
    "for batch in train_loader:\n",
    "  input_ids = batch['input_ids'].to(device)\n",
    "  mask = batch['attention_mask'].to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    teacher_out = teacher_model(input_ids, attention_mask = mask)\n",
    "    teacher_logits = teacher_out.logits\n",
    "\n",
    "  student_out = student_model(input_ids, attention_mask = mask)\n",
    "  students_logits = student_out.logits\n",
    "\n",
    "# KL divergence loss\n",
    "loss = F.kl_div(\n",
    "  input=F.log_softmax(student_logits, dim=-1),\n",
    "  target=F.softmax(teacher_logits, dim=-1),\n",
    "  reduction=\"batchmean\"\n",
    ")\n",
    "\n",
    "# backprop\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "if i%20 == 0:\n",
    "  torch.save(student_model.state_dict(), f\"student_checkpoint{i}.pt\")\n",
    "i = i + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c677e1a",
   "metadata": {},
   "source": [
    "**Save student Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6b6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8fcb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.save_pretrained(\"./student_model\")\n",
    "student_tokenizer.save_pretrained(\"./student_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
