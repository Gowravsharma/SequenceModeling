{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4210,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011876484560570071,
      "grad_norm": 3.0488057136535645,
      "learning_rate": 0.000198812351543943,
      "loss": 0.6886,
      "step": 50
    },
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 2.102623462677002,
      "learning_rate": 0.00019762470308788598,
      "loss": 0.6194,
      "step": 100
    },
    {
      "epoch": 0.035629453681710214,
      "grad_norm": 5.682379245758057,
      "learning_rate": 0.000196437054631829,
      "loss": 0.3666,
      "step": 150
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 3.9772109985351562,
      "learning_rate": 0.00019524940617577199,
      "loss": 0.3611,
      "step": 200
    },
    {
      "epoch": 0.05938242280285035,
      "grad_norm": 1.7248027324676514,
      "learning_rate": 0.00019406175771971497,
      "loss": 0.3147,
      "step": 250
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 2.6653919219970703,
      "learning_rate": 0.00019287410926365796,
      "loss": 0.3458,
      "step": 300
    },
    {
      "epoch": 0.0831353919239905,
      "grad_norm": 3.715712070465088,
      "learning_rate": 0.00019168646080760095,
      "loss": 0.3575,
      "step": 350
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 3.187990188598633,
      "learning_rate": 0.00019049881235154393,
      "loss": 0.2943,
      "step": 400
    },
    {
      "epoch": 0.10688836104513064,
      "grad_norm": 5.025196552276611,
      "learning_rate": 0.00018931116389548695,
      "loss": 0.3396,
      "step": 450
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 3.815854787826538,
      "learning_rate": 0.00018812351543942994,
      "loss": 0.3318,
      "step": 500
    },
    {
      "epoch": 0.13064133016627077,
      "grad_norm": 1.7534462213516235,
      "learning_rate": 0.00018693586698337292,
      "loss": 0.3069,
      "step": 550
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 1.9405521154403687,
      "learning_rate": 0.0001857482185273159,
      "loss": 0.3321,
      "step": 600
    },
    {
      "epoch": 0.1543942992874109,
      "grad_norm": 2.254689931869507,
      "learning_rate": 0.0001845605700712589,
      "loss": 0.2836,
      "step": 650
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 3.5206220149993896,
      "learning_rate": 0.0001833729216152019,
      "loss": 0.2839,
      "step": 700
    },
    {
      "epoch": 0.17814726840855108,
      "grad_norm": 2.3601107597351074,
      "learning_rate": 0.0001821852731591449,
      "loss": 0.2737,
      "step": 750
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 2.2614798545837402,
      "learning_rate": 0.00018099762470308789,
      "loss": 0.3125,
      "step": 800
    },
    {
      "epoch": 0.20190023752969122,
      "grad_norm": 2.3085744380950928,
      "learning_rate": 0.0001798099762470309,
      "loss": 0.3202,
      "step": 850
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 4.440337657928467,
      "learning_rate": 0.0001786223277909739,
      "loss": 0.3085,
      "step": 900
    },
    {
      "epoch": 0.22565320665083136,
      "grad_norm": 2.3583579063415527,
      "learning_rate": 0.00017743467933491687,
      "loss": 0.2917,
      "step": 950
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 2.7552294731140137,
      "learning_rate": 0.0001762470308788599,
      "loss": 0.2556,
      "step": 1000
    },
    {
      "epoch": 0.2494061757719715,
      "grad_norm": 3.6362497806549072,
      "learning_rate": 0.00017505938242280288,
      "loss": 0.2899,
      "step": 1050
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 2.2318313121795654,
      "learning_rate": 0.00017387173396674586,
      "loss": 0.2692,
      "step": 1100
    },
    {
      "epoch": 0.27315914489311166,
      "grad_norm": 1.7007628679275513,
      "learning_rate": 0.00017268408551068885,
      "loss": 0.2367,
      "step": 1150
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 4.570699691772461,
      "learning_rate": 0.00017149643705463184,
      "loss": 0.2531,
      "step": 1200
    },
    {
      "epoch": 0.29691211401425177,
      "grad_norm": 2.0232133865356445,
      "learning_rate": 0.00017030878859857482,
      "loss": 0.2857,
      "step": 1250
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 1.825514316558838,
      "learning_rate": 0.00016912114014251784,
      "loss": 0.2757,
      "step": 1300
    },
    {
      "epoch": 0.32066508313539194,
      "grad_norm": 1.2131361961364746,
      "learning_rate": 0.00016793349168646083,
      "loss": 0.2728,
      "step": 1350
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 2.1033713817596436,
      "learning_rate": 0.0001667458432304038,
      "loss": 0.2578,
      "step": 1400
    },
    {
      "epoch": 0.34441805225653205,
      "grad_norm": 1.1514441967010498,
      "learning_rate": 0.0001655581947743468,
      "loss": 0.2352,
      "step": 1450
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 2.5837957859039307,
      "learning_rate": 0.0001643705463182898,
      "loss": 0.2869,
      "step": 1500
    },
    {
      "epoch": 0.3681710213776722,
      "grad_norm": 1.288538932800293,
      "learning_rate": 0.0001631828978622328,
      "loss": 0.2859,
      "step": 1550
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 0.713743269443512,
      "learning_rate": 0.0001619952494061758,
      "loss": 0.2346,
      "step": 1600
    },
    {
      "epoch": 0.3919239904988123,
      "grad_norm": 1.7049311399459839,
      "learning_rate": 0.00016080760095011878,
      "loss": 0.2756,
      "step": 1650
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 4.706010341644287,
      "learning_rate": 0.00015961995249406176,
      "loss": 0.2401,
      "step": 1700
    },
    {
      "epoch": 0.4156769596199525,
      "grad_norm": 2.4767467975616455,
      "learning_rate": 0.00015843230403800475,
      "loss": 0.2546,
      "step": 1750
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 2.8886961936950684,
      "learning_rate": 0.00015724465558194774,
      "loss": 0.2577,
      "step": 1800
    },
    {
      "epoch": 0.43942992874109266,
      "grad_norm": 4.824239730834961,
      "learning_rate": 0.00015605700712589075,
      "loss": 0.2652,
      "step": 1850
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 3.324204444885254,
      "learning_rate": 0.00015486935866983374,
      "loss": 0.2523,
      "step": 1900
    },
    {
      "epoch": 0.46318289786223277,
      "grad_norm": 2.488396167755127,
      "learning_rate": 0.00015368171021377673,
      "loss": 0.2662,
      "step": 1950
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 3.8404688835144043,
      "learning_rate": 0.00015249406175771971,
      "loss": 0.2384,
      "step": 2000
    },
    {
      "epoch": 0.48693586698337293,
      "grad_norm": 1.328989863395691,
      "learning_rate": 0.0001513064133016627,
      "loss": 0.2887,
      "step": 2050
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 3.2779130935668945,
      "learning_rate": 0.0001501187648456057,
      "loss": 0.239,
      "step": 2100
    },
    {
      "epoch": 0.5106888361045131,
      "grad_norm": 1.4288957118988037,
      "learning_rate": 0.0001489311163895487,
      "loss": 0.2215,
      "step": 2150
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 2.736179828643799,
      "learning_rate": 0.0001477434679334917,
      "loss": 0.2524,
      "step": 2200
    },
    {
      "epoch": 0.5344418052256532,
      "grad_norm": 3.1318559646606445,
      "learning_rate": 0.00014655581947743468,
      "loss": 0.1992,
      "step": 2250
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 1.0961843729019165,
      "learning_rate": 0.00014536817102137766,
      "loss": 0.2299,
      "step": 2300
    },
    {
      "epoch": 0.5581947743467933,
      "grad_norm": 2.120047092437744,
      "learning_rate": 0.00014418052256532065,
      "loss": 0.2473,
      "step": 2350
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 3.599883794784546,
      "learning_rate": 0.00014299287410926367,
      "loss": 0.2303,
      "step": 2400
    },
    {
      "epoch": 0.5819477434679335,
      "grad_norm": 2.078430414199829,
      "learning_rate": 0.00014180522565320665,
      "loss": 0.2176,
      "step": 2450
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 3.570250988006592,
      "learning_rate": 0.00014061757719714964,
      "loss": 0.2435,
      "step": 2500
    },
    {
      "epoch": 0.6057007125890737,
      "grad_norm": 2.9892725944519043,
      "learning_rate": 0.00013942992874109265,
      "loss": 0.2532,
      "step": 2550
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 5.146878719329834,
      "learning_rate": 0.00013824228028503564,
      "loss": 0.2439,
      "step": 2600
    },
    {
      "epoch": 0.6294536817102138,
      "grad_norm": 0.9333909153938293,
      "learning_rate": 0.00013705463182897863,
      "loss": 0.2692,
      "step": 2650
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 0.8023058772087097,
      "learning_rate": 0.00013586698337292164,
      "loss": 0.2372,
      "step": 2700
    },
    {
      "epoch": 0.6532066508313539,
      "grad_norm": 2.464994430541992,
      "learning_rate": 0.00013467933491686463,
      "loss": 0.2725,
      "step": 2750
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 4.4205193519592285,
      "learning_rate": 0.00013349168646080762,
      "loss": 0.2236,
      "step": 2800
    },
    {
      "epoch": 0.6769596199524941,
      "grad_norm": 2.327852964401245,
      "learning_rate": 0.0001323040380047506,
      "loss": 0.2634,
      "step": 2850
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 1.944750428199768,
      "learning_rate": 0.0001311163895486936,
      "loss": 0.2529,
      "step": 2900
    },
    {
      "epoch": 0.7007125890736342,
      "grad_norm": 3.306727170944214,
      "learning_rate": 0.0001299287410926366,
      "loss": 0.2776,
      "step": 2950
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 1.9880448579788208,
      "learning_rate": 0.0001287410926365796,
      "loss": 0.2418,
      "step": 3000
    },
    {
      "epoch": 0.7244655581947743,
      "grad_norm": 0.8973040580749512,
      "learning_rate": 0.00012755344418052258,
      "loss": 0.2406,
      "step": 3050
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 2.3351335525512695,
      "learning_rate": 0.00012636579572446557,
      "loss": 0.2314,
      "step": 3100
    },
    {
      "epoch": 0.7482185273159145,
      "grad_norm": 0.9223633408546448,
      "learning_rate": 0.00012517814726840855,
      "loss": 0.2539,
      "step": 3150
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 1.1216697692871094,
      "learning_rate": 0.00012399049881235154,
      "loss": 0.2446,
      "step": 3200
    },
    {
      "epoch": 0.7719714964370546,
      "grad_norm": 2.950460433959961,
      "learning_rate": 0.00012280285035629456,
      "loss": 0.2159,
      "step": 3250
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 3.390166759490967,
      "learning_rate": 0.00012161520190023754,
      "loss": 0.2324,
      "step": 3300
    },
    {
      "epoch": 0.7957244655581948,
      "grad_norm": 4.4416303634643555,
      "learning_rate": 0.00012042755344418053,
      "loss": 0.2315,
      "step": 3350
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 3.5359137058258057,
      "learning_rate": 0.00011923990498812352,
      "loss": 0.2593,
      "step": 3400
    },
    {
      "epoch": 0.8194774346793349,
      "grad_norm": 1.1322250366210938,
      "learning_rate": 0.0001180522565320665,
      "loss": 0.2527,
      "step": 3450
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 1.9804928302764893,
      "learning_rate": 0.00011686460807600949,
      "loss": 0.2112,
      "step": 3500
    },
    {
      "epoch": 0.8432304038004751,
      "grad_norm": 2.353416681289673,
      "learning_rate": 0.0001156769596199525,
      "loss": 0.2215,
      "step": 3550
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 2.733745574951172,
      "learning_rate": 0.0001144893111638955,
      "loss": 0.2223,
      "step": 3600
    },
    {
      "epoch": 0.8669833729216152,
      "grad_norm": 0.5516433715820312,
      "learning_rate": 0.00011330166270783848,
      "loss": 0.2041,
      "step": 3650
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 1.5380364656448364,
      "learning_rate": 0.00011211401425178147,
      "loss": 0.2289,
      "step": 3700
    },
    {
      "epoch": 0.8907363420427553,
      "grad_norm": 3.421097993850708,
      "learning_rate": 0.00011092636579572447,
      "loss": 0.2353,
      "step": 3750
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 2.6336164474487305,
      "learning_rate": 0.00010973871733966747,
      "loss": 0.2479,
      "step": 3800
    },
    {
      "epoch": 0.9144893111638955,
      "grad_norm": 2.762859344482422,
      "learning_rate": 0.00010855106888361046,
      "loss": 0.2025,
      "step": 3850
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 0.7472591996192932,
      "learning_rate": 0.00010736342042755346,
      "loss": 0.1752,
      "step": 3900
    },
    {
      "epoch": 0.9382422802850356,
      "grad_norm": 3.1184747219085693,
      "learning_rate": 0.00010617577197149644,
      "loss": 0.2365,
      "step": 3950
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 1.6943812370300293,
      "learning_rate": 0.00010498812351543943,
      "loss": 0.2348,
      "step": 4000
    },
    {
      "epoch": 0.9619952494061758,
      "grad_norm": 0.912731945514679,
      "learning_rate": 0.00010380047505938242,
      "loss": 0.2099,
      "step": 4050
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 2.511709690093994,
      "learning_rate": 0.00010261282660332543,
      "loss": 0.2228,
      "step": 4100
    },
    {
      "epoch": 0.9857482185273159,
      "grad_norm": 1.0464062690734863,
      "learning_rate": 0.00010142517814726842,
      "loss": 0.2266,
      "step": 4150
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 2.656798839569092,
      "learning_rate": 0.00010023752969121141,
      "loss": 0.2401,
      "step": 4200
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.25549986958503723,
      "eval_runtime": 7.1568,
      "eval_samples_per_second": 121.843,
      "eval_steps_per_second": 7.685,
      "step": 4210
    }
  ],
  "logging_steps": 50,
  "max_steps": 8420,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4445400206146560.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
