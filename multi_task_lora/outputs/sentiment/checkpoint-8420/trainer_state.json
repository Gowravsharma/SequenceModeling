{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 8420,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011876484560570071,
      "grad_norm": 3.0488057136535645,
      "learning_rate": 0.000198812351543943,
      "loss": 0.6886,
      "step": 50
    },
    {
      "epoch": 0.023752969121140142,
      "grad_norm": 2.102623462677002,
      "learning_rate": 0.00019762470308788598,
      "loss": 0.6194,
      "step": 100
    },
    {
      "epoch": 0.035629453681710214,
      "grad_norm": 5.682379245758057,
      "learning_rate": 0.000196437054631829,
      "loss": 0.3666,
      "step": 150
    },
    {
      "epoch": 0.047505938242280284,
      "grad_norm": 3.9772109985351562,
      "learning_rate": 0.00019524940617577199,
      "loss": 0.3611,
      "step": 200
    },
    {
      "epoch": 0.05938242280285035,
      "grad_norm": 1.7248027324676514,
      "learning_rate": 0.00019406175771971497,
      "loss": 0.3147,
      "step": 250
    },
    {
      "epoch": 0.07125890736342043,
      "grad_norm": 2.6653919219970703,
      "learning_rate": 0.00019287410926365796,
      "loss": 0.3458,
      "step": 300
    },
    {
      "epoch": 0.0831353919239905,
      "grad_norm": 3.715712070465088,
      "learning_rate": 0.00019168646080760095,
      "loss": 0.3575,
      "step": 350
    },
    {
      "epoch": 0.09501187648456057,
      "grad_norm": 3.187990188598633,
      "learning_rate": 0.00019049881235154393,
      "loss": 0.2943,
      "step": 400
    },
    {
      "epoch": 0.10688836104513064,
      "grad_norm": 5.025196552276611,
      "learning_rate": 0.00018931116389548695,
      "loss": 0.3396,
      "step": 450
    },
    {
      "epoch": 0.1187648456057007,
      "grad_norm": 3.815854787826538,
      "learning_rate": 0.00018812351543942994,
      "loss": 0.3318,
      "step": 500
    },
    {
      "epoch": 0.13064133016627077,
      "grad_norm": 1.7534462213516235,
      "learning_rate": 0.00018693586698337292,
      "loss": 0.3069,
      "step": 550
    },
    {
      "epoch": 0.14251781472684086,
      "grad_norm": 1.9405521154403687,
      "learning_rate": 0.0001857482185273159,
      "loss": 0.3321,
      "step": 600
    },
    {
      "epoch": 0.1543942992874109,
      "grad_norm": 2.254689931869507,
      "learning_rate": 0.0001845605700712589,
      "loss": 0.2836,
      "step": 650
    },
    {
      "epoch": 0.166270783847981,
      "grad_norm": 3.5206220149993896,
      "learning_rate": 0.0001833729216152019,
      "loss": 0.2839,
      "step": 700
    },
    {
      "epoch": 0.17814726840855108,
      "grad_norm": 2.3601107597351074,
      "learning_rate": 0.0001821852731591449,
      "loss": 0.2737,
      "step": 750
    },
    {
      "epoch": 0.19002375296912113,
      "grad_norm": 2.2614798545837402,
      "learning_rate": 0.00018099762470308789,
      "loss": 0.3125,
      "step": 800
    },
    {
      "epoch": 0.20190023752969122,
      "grad_norm": 2.3085744380950928,
      "learning_rate": 0.0001798099762470309,
      "loss": 0.3202,
      "step": 850
    },
    {
      "epoch": 0.21377672209026127,
      "grad_norm": 4.440337657928467,
      "learning_rate": 0.0001786223277909739,
      "loss": 0.3085,
      "step": 900
    },
    {
      "epoch": 0.22565320665083136,
      "grad_norm": 2.3583579063415527,
      "learning_rate": 0.00017743467933491687,
      "loss": 0.2917,
      "step": 950
    },
    {
      "epoch": 0.2375296912114014,
      "grad_norm": 2.7552294731140137,
      "learning_rate": 0.0001762470308788599,
      "loss": 0.2556,
      "step": 1000
    },
    {
      "epoch": 0.2494061757719715,
      "grad_norm": 3.6362497806549072,
      "learning_rate": 0.00017505938242280288,
      "loss": 0.2899,
      "step": 1050
    },
    {
      "epoch": 0.26128266033254155,
      "grad_norm": 2.2318313121795654,
      "learning_rate": 0.00017387173396674586,
      "loss": 0.2692,
      "step": 1100
    },
    {
      "epoch": 0.27315914489311166,
      "grad_norm": 1.7007628679275513,
      "learning_rate": 0.00017268408551068885,
      "loss": 0.2367,
      "step": 1150
    },
    {
      "epoch": 0.2850356294536817,
      "grad_norm": 4.570699691772461,
      "learning_rate": 0.00017149643705463184,
      "loss": 0.2531,
      "step": 1200
    },
    {
      "epoch": 0.29691211401425177,
      "grad_norm": 2.0232133865356445,
      "learning_rate": 0.00017030878859857482,
      "loss": 0.2857,
      "step": 1250
    },
    {
      "epoch": 0.3087885985748218,
      "grad_norm": 1.825514316558838,
      "learning_rate": 0.00016912114014251784,
      "loss": 0.2757,
      "step": 1300
    },
    {
      "epoch": 0.32066508313539194,
      "grad_norm": 1.2131361961364746,
      "learning_rate": 0.00016793349168646083,
      "loss": 0.2728,
      "step": 1350
    },
    {
      "epoch": 0.332541567695962,
      "grad_norm": 2.1033713817596436,
      "learning_rate": 0.0001667458432304038,
      "loss": 0.2578,
      "step": 1400
    },
    {
      "epoch": 0.34441805225653205,
      "grad_norm": 1.1514441967010498,
      "learning_rate": 0.0001655581947743468,
      "loss": 0.2352,
      "step": 1450
    },
    {
      "epoch": 0.35629453681710216,
      "grad_norm": 2.5837957859039307,
      "learning_rate": 0.0001643705463182898,
      "loss": 0.2869,
      "step": 1500
    },
    {
      "epoch": 0.3681710213776722,
      "grad_norm": 1.288538932800293,
      "learning_rate": 0.0001631828978622328,
      "loss": 0.2859,
      "step": 1550
    },
    {
      "epoch": 0.38004750593824227,
      "grad_norm": 0.713743269443512,
      "learning_rate": 0.0001619952494061758,
      "loss": 0.2346,
      "step": 1600
    },
    {
      "epoch": 0.3919239904988123,
      "grad_norm": 1.7049311399459839,
      "learning_rate": 0.00016080760095011878,
      "loss": 0.2756,
      "step": 1650
    },
    {
      "epoch": 0.40380047505938244,
      "grad_norm": 4.706010341644287,
      "learning_rate": 0.00015961995249406176,
      "loss": 0.2401,
      "step": 1700
    },
    {
      "epoch": 0.4156769596199525,
      "grad_norm": 2.4767467975616455,
      "learning_rate": 0.00015843230403800475,
      "loss": 0.2546,
      "step": 1750
    },
    {
      "epoch": 0.42755344418052255,
      "grad_norm": 2.8886961936950684,
      "learning_rate": 0.00015724465558194774,
      "loss": 0.2577,
      "step": 1800
    },
    {
      "epoch": 0.43942992874109266,
      "grad_norm": 4.824239730834961,
      "learning_rate": 0.00015605700712589075,
      "loss": 0.2652,
      "step": 1850
    },
    {
      "epoch": 0.4513064133016627,
      "grad_norm": 3.324204444885254,
      "learning_rate": 0.00015486935866983374,
      "loss": 0.2523,
      "step": 1900
    },
    {
      "epoch": 0.46318289786223277,
      "grad_norm": 2.488396167755127,
      "learning_rate": 0.00015368171021377673,
      "loss": 0.2662,
      "step": 1950
    },
    {
      "epoch": 0.4750593824228028,
      "grad_norm": 3.8404688835144043,
      "learning_rate": 0.00015249406175771971,
      "loss": 0.2384,
      "step": 2000
    },
    {
      "epoch": 0.48693586698337293,
      "grad_norm": 1.328989863395691,
      "learning_rate": 0.0001513064133016627,
      "loss": 0.2887,
      "step": 2050
    },
    {
      "epoch": 0.498812351543943,
      "grad_norm": 3.2779130935668945,
      "learning_rate": 0.0001501187648456057,
      "loss": 0.239,
      "step": 2100
    },
    {
      "epoch": 0.5106888361045131,
      "grad_norm": 1.4288957118988037,
      "learning_rate": 0.0001489311163895487,
      "loss": 0.2215,
      "step": 2150
    },
    {
      "epoch": 0.5225653206650831,
      "grad_norm": 2.736179828643799,
      "learning_rate": 0.0001477434679334917,
      "loss": 0.2524,
      "step": 2200
    },
    {
      "epoch": 0.5344418052256532,
      "grad_norm": 3.1318559646606445,
      "learning_rate": 0.00014655581947743468,
      "loss": 0.1992,
      "step": 2250
    },
    {
      "epoch": 0.5463182897862233,
      "grad_norm": 1.0961843729019165,
      "learning_rate": 0.00014536817102137766,
      "loss": 0.2299,
      "step": 2300
    },
    {
      "epoch": 0.5581947743467933,
      "grad_norm": 2.120047092437744,
      "learning_rate": 0.00014418052256532065,
      "loss": 0.2473,
      "step": 2350
    },
    {
      "epoch": 0.5700712589073634,
      "grad_norm": 3.599883794784546,
      "learning_rate": 0.00014299287410926367,
      "loss": 0.2303,
      "step": 2400
    },
    {
      "epoch": 0.5819477434679335,
      "grad_norm": 2.078430414199829,
      "learning_rate": 0.00014180522565320665,
      "loss": 0.2176,
      "step": 2450
    },
    {
      "epoch": 0.5938242280285035,
      "grad_norm": 3.570250988006592,
      "learning_rate": 0.00014061757719714964,
      "loss": 0.2435,
      "step": 2500
    },
    {
      "epoch": 0.6057007125890737,
      "grad_norm": 2.9892725944519043,
      "learning_rate": 0.00013942992874109265,
      "loss": 0.2532,
      "step": 2550
    },
    {
      "epoch": 0.6175771971496437,
      "grad_norm": 5.146878719329834,
      "learning_rate": 0.00013824228028503564,
      "loss": 0.2439,
      "step": 2600
    },
    {
      "epoch": 0.6294536817102138,
      "grad_norm": 0.9333909153938293,
      "learning_rate": 0.00013705463182897863,
      "loss": 0.2692,
      "step": 2650
    },
    {
      "epoch": 0.6413301662707839,
      "grad_norm": 0.8023058772087097,
      "learning_rate": 0.00013586698337292164,
      "loss": 0.2372,
      "step": 2700
    },
    {
      "epoch": 0.6532066508313539,
      "grad_norm": 2.464994430541992,
      "learning_rate": 0.00013467933491686463,
      "loss": 0.2725,
      "step": 2750
    },
    {
      "epoch": 0.665083135391924,
      "grad_norm": 4.4205193519592285,
      "learning_rate": 0.00013349168646080762,
      "loss": 0.2236,
      "step": 2800
    },
    {
      "epoch": 0.6769596199524941,
      "grad_norm": 2.327852964401245,
      "learning_rate": 0.0001323040380047506,
      "loss": 0.2634,
      "step": 2850
    },
    {
      "epoch": 0.6888361045130641,
      "grad_norm": 1.944750428199768,
      "learning_rate": 0.0001311163895486936,
      "loss": 0.2529,
      "step": 2900
    },
    {
      "epoch": 0.7007125890736342,
      "grad_norm": 3.306727170944214,
      "learning_rate": 0.0001299287410926366,
      "loss": 0.2776,
      "step": 2950
    },
    {
      "epoch": 0.7125890736342043,
      "grad_norm": 1.9880448579788208,
      "learning_rate": 0.0001287410926365796,
      "loss": 0.2418,
      "step": 3000
    },
    {
      "epoch": 0.7244655581947743,
      "grad_norm": 0.8973040580749512,
      "learning_rate": 0.00012755344418052258,
      "loss": 0.2406,
      "step": 3050
    },
    {
      "epoch": 0.7363420427553444,
      "grad_norm": 2.3351335525512695,
      "learning_rate": 0.00012636579572446557,
      "loss": 0.2314,
      "step": 3100
    },
    {
      "epoch": 0.7482185273159145,
      "grad_norm": 0.9223633408546448,
      "learning_rate": 0.00012517814726840855,
      "loss": 0.2539,
      "step": 3150
    },
    {
      "epoch": 0.7600950118764845,
      "grad_norm": 1.1216697692871094,
      "learning_rate": 0.00012399049881235154,
      "loss": 0.2446,
      "step": 3200
    },
    {
      "epoch": 0.7719714964370546,
      "grad_norm": 2.950460433959961,
      "learning_rate": 0.00012280285035629456,
      "loss": 0.2159,
      "step": 3250
    },
    {
      "epoch": 0.7838479809976246,
      "grad_norm": 3.390166759490967,
      "learning_rate": 0.00012161520190023754,
      "loss": 0.2324,
      "step": 3300
    },
    {
      "epoch": 0.7957244655581948,
      "grad_norm": 4.4416303634643555,
      "learning_rate": 0.00012042755344418053,
      "loss": 0.2315,
      "step": 3350
    },
    {
      "epoch": 0.8076009501187649,
      "grad_norm": 3.5359137058258057,
      "learning_rate": 0.00011923990498812352,
      "loss": 0.2593,
      "step": 3400
    },
    {
      "epoch": 0.8194774346793349,
      "grad_norm": 1.1322250366210938,
      "learning_rate": 0.0001180522565320665,
      "loss": 0.2527,
      "step": 3450
    },
    {
      "epoch": 0.831353919239905,
      "grad_norm": 1.9804928302764893,
      "learning_rate": 0.00011686460807600949,
      "loss": 0.2112,
      "step": 3500
    },
    {
      "epoch": 0.8432304038004751,
      "grad_norm": 2.353416681289673,
      "learning_rate": 0.0001156769596199525,
      "loss": 0.2215,
      "step": 3550
    },
    {
      "epoch": 0.8551068883610451,
      "grad_norm": 2.733745574951172,
      "learning_rate": 0.0001144893111638955,
      "loss": 0.2223,
      "step": 3600
    },
    {
      "epoch": 0.8669833729216152,
      "grad_norm": 0.5516433715820312,
      "learning_rate": 0.00011330166270783848,
      "loss": 0.2041,
      "step": 3650
    },
    {
      "epoch": 0.8788598574821853,
      "grad_norm": 1.5380364656448364,
      "learning_rate": 0.00011211401425178147,
      "loss": 0.2289,
      "step": 3700
    },
    {
      "epoch": 0.8907363420427553,
      "grad_norm": 3.421097993850708,
      "learning_rate": 0.00011092636579572447,
      "loss": 0.2353,
      "step": 3750
    },
    {
      "epoch": 0.9026128266033254,
      "grad_norm": 2.6336164474487305,
      "learning_rate": 0.00010973871733966747,
      "loss": 0.2479,
      "step": 3800
    },
    {
      "epoch": 0.9144893111638955,
      "grad_norm": 2.762859344482422,
      "learning_rate": 0.00010855106888361046,
      "loss": 0.2025,
      "step": 3850
    },
    {
      "epoch": 0.9263657957244655,
      "grad_norm": 0.7472591996192932,
      "learning_rate": 0.00010736342042755346,
      "loss": 0.1752,
      "step": 3900
    },
    {
      "epoch": 0.9382422802850356,
      "grad_norm": 3.1184747219085693,
      "learning_rate": 0.00010617577197149644,
      "loss": 0.2365,
      "step": 3950
    },
    {
      "epoch": 0.9501187648456056,
      "grad_norm": 1.6943812370300293,
      "learning_rate": 0.00010498812351543943,
      "loss": 0.2348,
      "step": 4000
    },
    {
      "epoch": 0.9619952494061758,
      "grad_norm": 0.912731945514679,
      "learning_rate": 0.00010380047505938242,
      "loss": 0.2099,
      "step": 4050
    },
    {
      "epoch": 0.9738717339667459,
      "grad_norm": 2.511709690093994,
      "learning_rate": 0.00010261282660332543,
      "loss": 0.2228,
      "step": 4100
    },
    {
      "epoch": 0.9857482185273159,
      "grad_norm": 1.0464062690734863,
      "learning_rate": 0.00010142517814726842,
      "loss": 0.2266,
      "step": 4150
    },
    {
      "epoch": 0.997624703087886,
      "grad_norm": 2.656798839569092,
      "learning_rate": 0.00010023752969121141,
      "loss": 0.2401,
      "step": 4200
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.25549986958503723,
      "eval_runtime": 7.1568,
      "eval_samples_per_second": 121.843,
      "eval_steps_per_second": 7.685,
      "step": 4210
    },
    {
      "epoch": 1.009501187648456,
      "grad_norm": 1.5076414346694946,
      "learning_rate": 9.90498812351544e-05,
      "loss": 0.252,
      "step": 4250
    },
    {
      "epoch": 1.0213776722090262,
      "grad_norm": 5.0817766189575195,
      "learning_rate": 9.78622327790974e-05,
      "loss": 0.2055,
      "step": 4300
    },
    {
      "epoch": 1.0332541567695963,
      "grad_norm": 2.9698994159698486,
      "learning_rate": 9.667458432304038e-05,
      "loss": 0.1957,
      "step": 4350
    },
    {
      "epoch": 1.0451306413301662,
      "grad_norm": 4.143115520477295,
      "learning_rate": 9.548693586698337e-05,
      "loss": 0.2652,
      "step": 4400
    },
    {
      "epoch": 1.0570071258907363,
      "grad_norm": 3.7384774684906006,
      "learning_rate": 9.429928741092637e-05,
      "loss": 0.1703,
      "step": 4450
    },
    {
      "epoch": 1.0688836104513064,
      "grad_norm": 1.9511655569076538,
      "learning_rate": 9.311163895486936e-05,
      "loss": 0.2136,
      "step": 4500
    },
    {
      "epoch": 1.0807600950118765,
      "grad_norm": 4.1592230796813965,
      "learning_rate": 9.192399049881234e-05,
      "loss": 0.2059,
      "step": 4550
    },
    {
      "epoch": 1.0926365795724466,
      "grad_norm": 3.932079553604126,
      "learning_rate": 9.073634204275535e-05,
      "loss": 0.2093,
      "step": 4600
    },
    {
      "epoch": 1.1045130641330165,
      "grad_norm": 0.9965311288833618,
      "learning_rate": 8.954869358669835e-05,
      "loss": 0.1964,
      "step": 4650
    },
    {
      "epoch": 1.1163895486935866,
      "grad_norm": 3.367122173309326,
      "learning_rate": 8.836104513064133e-05,
      "loss": 0.1741,
      "step": 4700
    },
    {
      "epoch": 1.1282660332541568,
      "grad_norm": 1.7474939823150635,
      "learning_rate": 8.717339667458433e-05,
      "loss": 0.2282,
      "step": 4750
    },
    {
      "epoch": 1.1401425178147269,
      "grad_norm": 1.623361349105835,
      "learning_rate": 8.598574821852732e-05,
      "loss": 0.1902,
      "step": 4800
    },
    {
      "epoch": 1.152019002375297,
      "grad_norm": 3.9728198051452637,
      "learning_rate": 8.479809976247032e-05,
      "loss": 0.2047,
      "step": 4850
    },
    {
      "epoch": 1.1638954869358669,
      "grad_norm": 2.132510185241699,
      "learning_rate": 8.361045130641331e-05,
      "loss": 0.2398,
      "step": 4900
    },
    {
      "epoch": 1.175771971496437,
      "grad_norm": 0.9307164549827576,
      "learning_rate": 8.24228028503563e-05,
      "loss": 0.2221,
      "step": 4950
    },
    {
      "epoch": 1.187648456057007,
      "grad_norm": 1.3986594676971436,
      "learning_rate": 8.12351543942993e-05,
      "loss": 0.2037,
      "step": 5000
    },
    {
      "epoch": 1.1995249406175772,
      "grad_norm": 4.182613849639893,
      "learning_rate": 8.004750593824228e-05,
      "loss": 0.2296,
      "step": 5050
    },
    {
      "epoch": 1.2114014251781473,
      "grad_norm": 2.2097456455230713,
      "learning_rate": 7.885985748218527e-05,
      "loss": 0.2235,
      "step": 5100
    },
    {
      "epoch": 1.2232779097387174,
      "grad_norm": 1.2111268043518066,
      "learning_rate": 7.767220902612827e-05,
      "loss": 0.181,
      "step": 5150
    },
    {
      "epoch": 1.2351543942992875,
      "grad_norm": 1.9847744703292847,
      "learning_rate": 7.648456057007126e-05,
      "loss": 0.2299,
      "step": 5200
    },
    {
      "epoch": 1.2470308788598574,
      "grad_norm": 5.116684436798096,
      "learning_rate": 7.529691211401425e-05,
      "loss": 0.2191,
      "step": 5250
    },
    {
      "epoch": 1.2589073634204275,
      "grad_norm": 3.2706706523895264,
      "learning_rate": 7.410926365795725e-05,
      "loss": 0.2118,
      "step": 5300
    },
    {
      "epoch": 1.2707838479809976,
      "grad_norm": 2.0472240447998047,
      "learning_rate": 7.292161520190023e-05,
      "loss": 0.208,
      "step": 5350
    },
    {
      "epoch": 1.2826603325415677,
      "grad_norm": 0.41345715522766113,
      "learning_rate": 7.173396674584324e-05,
      "loss": 0.229,
      "step": 5400
    },
    {
      "epoch": 1.2945368171021379,
      "grad_norm": 4.008819580078125,
      "learning_rate": 7.054631828978622e-05,
      "loss": 0.1955,
      "step": 5450
    },
    {
      "epoch": 1.3064133016627077,
      "grad_norm": 3.7213804721832275,
      "learning_rate": 6.935866983372922e-05,
      "loss": 0.2077,
      "step": 5500
    },
    {
      "epoch": 1.3182897862232779,
      "grad_norm": 1.237157940864563,
      "learning_rate": 6.817102137767222e-05,
      "loss": 0.2376,
      "step": 5550
    },
    {
      "epoch": 1.330166270783848,
      "grad_norm": 2.2310614585876465,
      "learning_rate": 6.698337292161521e-05,
      "loss": 0.1942,
      "step": 5600
    },
    {
      "epoch": 1.342042755344418,
      "grad_norm": 2.759582281112671,
      "learning_rate": 6.57957244655582e-05,
      "loss": 0.2126,
      "step": 5650
    },
    {
      "epoch": 1.3539192399049882,
      "grad_norm": 1.5486890077590942,
      "learning_rate": 6.46080760095012e-05,
      "loss": 0.1737,
      "step": 5700
    },
    {
      "epoch": 1.365795724465558,
      "grad_norm": 2.4921460151672363,
      "learning_rate": 6.342042755344419e-05,
      "loss": 0.18,
      "step": 5750
    },
    {
      "epoch": 1.3776722090261282,
      "grad_norm": 2.981954336166382,
      "learning_rate": 6.223277909738717e-05,
      "loss": 0.1664,
      "step": 5800
    },
    {
      "epoch": 1.3895486935866983,
      "grad_norm": 2.6826462745666504,
      "learning_rate": 6.104513064133017e-05,
      "loss": 0.1977,
      "step": 5850
    },
    {
      "epoch": 1.4014251781472684,
      "grad_norm": 0.4396163523197174,
      "learning_rate": 5.985748218527316e-05,
      "loss": 0.182,
      "step": 5900
    },
    {
      "epoch": 1.4133016627078385,
      "grad_norm": 1.5352178812026978,
      "learning_rate": 5.866983372921615e-05,
      "loss": 0.1994,
      "step": 5950
    },
    {
      "epoch": 1.4251781472684084,
      "grad_norm": 4.121391773223877,
      "learning_rate": 5.748218527315915e-05,
      "loss": 0.1817,
      "step": 6000
    },
    {
      "epoch": 1.4370546318289787,
      "grad_norm": 3.6143887042999268,
      "learning_rate": 5.6294536817102136e-05,
      "loss": 0.1751,
      "step": 6050
    },
    {
      "epoch": 1.4489311163895486,
      "grad_norm": 1.9057646989822388,
      "learning_rate": 5.510688836104513e-05,
      "loss": 0.2037,
      "step": 6100
    },
    {
      "epoch": 1.4608076009501187,
      "grad_norm": 1.2632876634597778,
      "learning_rate": 5.391923990498813e-05,
      "loss": 0.1968,
      "step": 6150
    },
    {
      "epoch": 1.4726840855106889,
      "grad_norm": 3.923947334289551,
      "learning_rate": 5.273159144893112e-05,
      "loss": 0.1593,
      "step": 6200
    },
    {
      "epoch": 1.484560570071259,
      "grad_norm": 2.788814067840576,
      "learning_rate": 5.154394299287412e-05,
      "loss": 0.2152,
      "step": 6250
    },
    {
      "epoch": 1.496437054631829,
      "grad_norm": 4.754542827606201,
      "learning_rate": 5.0356294536817106e-05,
      "loss": 0.2007,
      "step": 6300
    },
    {
      "epoch": 1.508313539192399,
      "grad_norm": 3.802018642425537,
      "learning_rate": 4.9168646080760093e-05,
      "loss": 0.1882,
      "step": 6350
    },
    {
      "epoch": 1.520190023752969,
      "grad_norm": 3.441638231277466,
      "learning_rate": 4.798099762470309e-05,
      "loss": 0.2114,
      "step": 6400
    },
    {
      "epoch": 1.5320665083135392,
      "grad_norm": 1.7676335573196411,
      "learning_rate": 4.679334916864608e-05,
      "loss": 0.1788,
      "step": 6450
    },
    {
      "epoch": 1.5439429928741093,
      "grad_norm": 3.6550819873809814,
      "learning_rate": 4.5605700712589075e-05,
      "loss": 0.2257,
      "step": 6500
    },
    {
      "epoch": 1.5558194774346794,
      "grad_norm": 2.067042589187622,
      "learning_rate": 4.441805225653207e-05,
      "loss": 0.1983,
      "step": 6550
    },
    {
      "epoch": 1.5676959619952493,
      "grad_norm": 2.8308682441711426,
      "learning_rate": 4.323040380047506e-05,
      "loss": 0.1857,
      "step": 6600
    },
    {
      "epoch": 1.5795724465558196,
      "grad_norm": 1.0547987222671509,
      "learning_rate": 4.204275534441806e-05,
      "loss": 0.2274,
      "step": 6650
    },
    {
      "epoch": 1.5914489311163895,
      "grad_norm": 0.7487334609031677,
      "learning_rate": 4.0855106888361044e-05,
      "loss": 0.1954,
      "step": 6700
    },
    {
      "epoch": 1.6033254156769596,
      "grad_norm": 4.387979984283447,
      "learning_rate": 3.966745843230404e-05,
      "loss": 0.1666,
      "step": 6750
    },
    {
      "epoch": 1.6152019002375297,
      "grad_norm": 5.927844047546387,
      "learning_rate": 3.847980997624703e-05,
      "loss": 0.2542,
      "step": 6800
    },
    {
      "epoch": 1.6270783847980996,
      "grad_norm": 2.5289177894592285,
      "learning_rate": 3.7292161520190026e-05,
      "loss": 0.207,
      "step": 6850
    },
    {
      "epoch": 1.63895486935867,
      "grad_norm": 2.2761573791503906,
      "learning_rate": 3.6104513064133013e-05,
      "loss": 0.237,
      "step": 6900
    },
    {
      "epoch": 1.6508313539192399,
      "grad_norm": 1.0969892740249634,
      "learning_rate": 3.4916864608076014e-05,
      "loss": 0.1839,
      "step": 6950
    },
    {
      "epoch": 1.66270783847981,
      "grad_norm": 1.231074333190918,
      "learning_rate": 3.372921615201901e-05,
      "loss": 0.2278,
      "step": 7000
    },
    {
      "epoch": 1.67458432304038,
      "grad_norm": 1.5720099210739136,
      "learning_rate": 3.2541567695961995e-05,
      "loss": 0.1351,
      "step": 7050
    },
    {
      "epoch": 1.68646080760095,
      "grad_norm": 1.4800153970718384,
      "learning_rate": 3.135391923990499e-05,
      "loss": 0.1766,
      "step": 7100
    },
    {
      "epoch": 1.6983372921615203,
      "grad_norm": 1.3200364112854004,
      "learning_rate": 3.0166270783847983e-05,
      "loss": 0.204,
      "step": 7150
    },
    {
      "epoch": 1.7102137767220902,
      "grad_norm": 2.1734986305236816,
      "learning_rate": 2.8978622327790977e-05,
      "loss": 0.1899,
      "step": 7200
    },
    {
      "epoch": 1.7220902612826603,
      "grad_norm": 0.319349080324173,
      "learning_rate": 2.7790973871733968e-05,
      "loss": 0.2244,
      "step": 7250
    },
    {
      "epoch": 1.7339667458432304,
      "grad_norm": 2.7158408164978027,
      "learning_rate": 2.6603325415676962e-05,
      "loss": 0.1978,
      "step": 7300
    },
    {
      "epoch": 1.7458432304038005,
      "grad_norm": 1.2231312990188599,
      "learning_rate": 2.5415676959619956e-05,
      "loss": 0.1722,
      "step": 7350
    },
    {
      "epoch": 1.7577197149643706,
      "grad_norm": 0.592478334903717,
      "learning_rate": 2.4228028503562946e-05,
      "loss": 0.1824,
      "step": 7400
    },
    {
      "epoch": 1.7695961995249405,
      "grad_norm": 2.5857818126678467,
      "learning_rate": 2.3040380047505937e-05,
      "loss": 0.1887,
      "step": 7450
    },
    {
      "epoch": 1.7814726840855108,
      "grad_norm": 2.4476442337036133,
      "learning_rate": 2.1852731591448934e-05,
      "loss": 0.2025,
      "step": 7500
    },
    {
      "epoch": 1.7933491686460807,
      "grad_norm": 4.450299263000488,
      "learning_rate": 2.0665083135391925e-05,
      "loss": 0.2371,
      "step": 7550
    },
    {
      "epoch": 1.8052256532066508,
      "grad_norm": 2.317319393157959,
      "learning_rate": 1.947743467933492e-05,
      "loss": 0.168,
      "step": 7600
    },
    {
      "epoch": 1.817102137767221,
      "grad_norm": 3.72292160987854,
      "learning_rate": 1.828978622327791e-05,
      "loss": 0.1991,
      "step": 7650
    },
    {
      "epoch": 1.8289786223277908,
      "grad_norm": 0.32233700156211853,
      "learning_rate": 1.7102137767220903e-05,
      "loss": 0.1978,
      "step": 7700
    },
    {
      "epoch": 1.8408551068883612,
      "grad_norm": 0.2943108379840851,
      "learning_rate": 1.5914489311163897e-05,
      "loss": 0.1875,
      "step": 7750
    },
    {
      "epoch": 1.852731591448931,
      "grad_norm": 2.48117995262146,
      "learning_rate": 1.4726840855106888e-05,
      "loss": 0.161,
      "step": 7800
    },
    {
      "epoch": 1.8646080760095012,
      "grad_norm": 3.24613094329834,
      "learning_rate": 1.3539192399049882e-05,
      "loss": 0.1806,
      "step": 7850
    },
    {
      "epoch": 1.8764845605700713,
      "grad_norm": 2.8889505863189697,
      "learning_rate": 1.2351543942992874e-05,
      "loss": 0.1717,
      "step": 7900
    },
    {
      "epoch": 1.8883610451306412,
      "grad_norm": 2.4566078186035156,
      "learning_rate": 1.1163895486935868e-05,
      "loss": 0.2127,
      "step": 7950
    },
    {
      "epoch": 1.9002375296912115,
      "grad_norm": 3.30130672454834,
      "learning_rate": 9.97624703087886e-06,
      "loss": 0.1816,
      "step": 8000
    },
    {
      "epoch": 1.9121140142517814,
      "grad_norm": 2.974808692932129,
      "learning_rate": 8.788598574821852e-06,
      "loss": 0.2047,
      "step": 8050
    },
    {
      "epoch": 1.9239904988123515,
      "grad_norm": 3.7443835735321045,
      "learning_rate": 7.6009501187648464e-06,
      "loss": 0.2343,
      "step": 8100
    },
    {
      "epoch": 1.9358669833729216,
      "grad_norm": 0.4122924506664276,
      "learning_rate": 6.4133016627078396e-06,
      "loss": 0.1763,
      "step": 8150
    },
    {
      "epoch": 1.9477434679334917,
      "grad_norm": 4.0651631355285645,
      "learning_rate": 5.225653206650832e-06,
      "loss": 0.1907,
      "step": 8200
    },
    {
      "epoch": 1.9596199524940618,
      "grad_norm": 0.8210325241088867,
      "learning_rate": 4.038004750593825e-06,
      "loss": 0.1639,
      "step": 8250
    },
    {
      "epoch": 1.9714964370546317,
      "grad_norm": 1.2720024585723877,
      "learning_rate": 2.850356294536817e-06,
      "loss": 0.1749,
      "step": 8300
    },
    {
      "epoch": 1.9833729216152018,
      "grad_norm": 5.459990978240967,
      "learning_rate": 1.6627078384798101e-06,
      "loss": 0.2102,
      "step": 8350
    },
    {
      "epoch": 1.995249406175772,
      "grad_norm": 2.301307201385498,
      "learning_rate": 4.750593824228029e-07,
      "loss": 0.1686,
      "step": 8400
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.2607646584510803,
      "eval_runtime": 7.1553,
      "eval_samples_per_second": 121.869,
      "eval_steps_per_second": 7.687,
      "step": 8420
    }
  ],
  "logging_steps": 50,
  "max_steps": 8420,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8890800412293120.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
